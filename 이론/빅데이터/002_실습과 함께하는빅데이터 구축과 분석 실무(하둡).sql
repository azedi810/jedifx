 
/* ############################################################################
*  빅데이터 쉽게 이해하기
##############################################################################*/

/*****************************************************
*   101.빅데이터 개념 및 성공사례 
******************************************************/
1. 빅데이터의 개념
   - 현재는 상업적 마케팅ㅇ 용어로 변화 
   - 크리,   처리방식(병렬)   :   모두 만족  BIG DATA
   - 분산파일시스템 , 병렬처리 프레임워크 가지 있어야 한다.  
   - 대표적인 시스템 하둡 hadoop 
   
2. 빅데이터란
   - data 의미 : 데이터 다루는 기술 : dbms  주로 rdbms
   - 데이터 저장 검색 수정 삭제 
   - crud  : retrieve(검색)  주로 테이블 레코드 형태로 관리 
      - R : 데이터의 빠른 검색을 중심으로 최적화되어 있다.  데이터 변경보다 검색의 빈도가 압도적으로 많다.
        index 외 같은 보조 자료구조를 이미 만들어두고 검색에 사용해 검속 속도를 높인다. 
   
3. RDBMS   와  NoSQL 비교
    - DBMS 빠른 읽기 최적화  index 수정
    - NoSQL 등장 : 빠른 쓰기 최적
    - 하지만 양쪽 다 데이터가 커지는 경우 특수한 처리 필요 : 수십테라가 넘는 경우
    - 빅데이터는 일반적인 파일로 관리 (키/밸류 방식)
    
4. 빅데이터와 DBMS/NoSQL 차이점
   -  Big 의미 : 크기 
   - 일반 DBMS  : Large 데이터 다툼
   - Very Large DB  :  VLDB  : 조인이 거의 안됨 ,  역정규화 (Denormalize)  저장양이 많다   
       : 파티셔닝, 샤딩, 복제   -->  
       : 정규화 (데이터 중복 방지)
  - Big Data  :  VLDB 보다 크다  , 서버 수십대, 수백대, 수천대  , 데이터 분산 저장
      - 일반 DBMS 로 처리하려면 엄청난 비용 
      - 수십테라 이상 
      - 일반적인 DBMS 처리 못하는 것들
      - 서버 한 대로 처리할 수 없는 규모의 데이터  ( 예  10TB 쇼팅 1대 서버)
      - 기존 소프트웨어로 처리할 수 없는 규모의 데이터 
           
5. 빅데이터 성공 사례 
  - 데이터마이닝 :  넷플릭스 사례(영화 추천, 고객 만족도 높다, 영화카테고리, 배우 등)
      , 페이스북, 트위터
      , 월마트(상황 분석, 물건간의 상황, 주말-맥주 등  분석해서 동선 판매 위치 변경 성공)
  - 제일 문제는 데이터 :  데이터 주로 소유가 있음 : 자유롭게 유통 되지 않음
  - 작은 비용을 분석
  - 거의 유료가 없고, 오픈소스라 별다른 비용이 들지 않음 
  
   빅데이터 기술의 핵심은 여러 개의 시스템을 묶는 빅파일시스템인 HDFS (하둡시스템)와 분산처리 프레임워크인 맵리듀스(MapReduce)라고 할 수 있습니다
   멀티코어 시스템에서 여러 개의 코어를 활용하려면 멀티스레드 프로그래밍을 해야 합니다.
   이 방법은 하느이 코어만 사용하는 일반 프로그래밍보다 훨씬 복잡합니다.
   동기화라고 부르는 기술에 대한 이해가 필수 
   더욱이 데드락 deadlock 이라고 부르는 현상을 잡기는 굉장히 힘듬
   이를 DBMS에서 트랜잭션의 격리 isolation 라는 무제로 다룹니다.
   하지만 멀티스레드 프로그래밍을 하더라도 하나의 시스템의 범주를 벗어나기 흠듭니다.
   여러대의 시스템에 작업을 나누어주고 이를 취합하는 기술은 나이도가 괴장히 높습니다.
   그리고 일단 처리대상 데이터를 저장해야하는데 이를 분산저장하는 기술도 쉽지 않습니다
   즉 하둡의 핵심기술인 HDFS와 맵리듀스는 일반적인 개발가 다루기는 굉장히 복잡
   합둡은  개발자는 단진 HDFS 파일을 업로드 , 맵리듀스 작업에 대한 클래스만 프로그래밍해주면 됨 
   하둡은 오픈소스기술로 별도의 비용없이 사용, 
   초기에는 작게 시작했다가 시스템이 더 필요하면 간단한 작업으로 계속 스케일을 키울 수 있다 .
   
   
/*****************************************************
* 빅데이터 프레임워크 - 하둡 개요 및 아키텍처
******************************************************/
 1. 하둡의 역사
   - 더그 커팅  : 하둡의 아버지 , 루씬 제작자(검색엔진용 오픈 소스) . 구급의 영감을 얻어 
      10년 이상 개발된 빅데이터 처리를 위한 자바기반의 분산파일시스템 + 병렬처리 프레임워크 
   - 2003 : the google file system 논문 
   - mapreduce : 2004 : simplified data processing on large cluster    논문
   - 2006년 부터 제작 : apache top level project
   - 야후에 취직 -> 클라우데라로 이직
   - GFS ->HDFS ,   MapReduce -> MapReduce 
   - 노란색 코끼리 
   - Hadoop, Mahout(코끼리를 모는 사람), Oozie, Horton 
   
2. 하둡의 기초 사항
  - JAVA 로 만듦 :   
  - 유닉스 기반, 리눅스 중 우분투 기반으로 수업 진행
  - 배포판 : apache hadoop, CDH (믈라우데라판),  HDP (호튼웍스판)
  - 빅 3회사  : apache 재단  하둡 표준,  클라우데라(claudera : 가장크다)
                    호튼윅스(hortonworks) 야후 퇴사 후 
                    맵알 (MapR)
 3. 하둡의 특징
   - 오픈소스 , github 
   - 데이터가 있는 곳으로 코드를 이동
   - scale out  : 병렬 처리 ...서버를 하나씩 증가하는 방식 ==> 시스템을 지속 추가확장 가능한 스케일아웃구
   - 병렬처리를 가능하게 하는 단순한 데이터 모델
   - 오프라인 배치 프로세싱에 최적화 :  실시간 처리 안됨 
   
######. 하둡 아키텍처
  - 하둡  :    HDFS + MapReduce 
  - 빅파일시스템 HDFS  (Hadoop File System)
       - 네임노드(마스터) / 테이터노드 (슬레이브)  
           - 세컨더리 네임노드(보조네임노드사용 - 네임노드가 죽으면 서비스 장애가 생김) 
              : SPOF (single point of failure) 문제
   - 분산처리 프레임워크 : MapReduce
           - 잡트래커(마스터) / 태스트래커(슬레이브)

1. HDFS  
 - 고가용성 HA  high availiability   동일한 데이터블럭을 여러 번 복제해서 
    장애에도 문제없이 작동 가능하도록 만듬 
 - 하나의 HDFS 하나의 네임스페이스 제공 :  논리적 하나
 - 파일을 여러 개의 블럭으로 나누어 저장
 - 블록사이즈 : 64M   실제로 128M 많이 사용함
 - 큰 파일을 다루는 데 적합
 - 운영체제의 파일 시스템을 그대로 사용함.    포멧없이 사용
 - 복제수 (Replication Factor)  :  북제수가 3개면 3개 복제 : 장애 발생 시 괜찮다.
	 여러 군데에 같은 블럭을 복사    (HA)
 - file overWrite 형태로 구성됨 : 덮어씌운다.
 - 네임노드 +  데이터노드 
 
2. MapReduce
 - 잡트래커 + 태스크트래커 
    : 입력데이터 출력 HDFS 상에 존재 
 
3. MapReduce 프레임워크
 - word count process
   :  splitting      mapping       shuffling     reducing(복수 단어를 한단어로 줄여준다)       final result    
   
4. 스파크 기술과 하둡의 차이점에 대해서 적으시오   
   
/*****************************************************
* 3. 빅데이터 프레임워크 - 하둡 설치 및 준비사항(환경설정) 
******************************************************/
1. 설치 전제 조건
 - 하이퍼바이저 
     - 하이퍼바이저(버추얼박스)를 기반으로 리눅스(우분투)를 설치
     - Vagrant 사용해 설치를 자동화한다.
     - 도커(컨테이너기반)도 가능하지만 사용하는 법이 다르다.... 
 - 윈도우에 설치 : 하이퍼바이저나 도커 설치 (리눅스 인스톨)
 - 리눅스/유닉스 계열에서 네이티브로 바로 설치와 수행이 가능하다.  
 - 우분투 서버 이미지 다운로드   ubuntu  
  
2. vagrantup.com 바그란트   vagrant  
 - vagrnt int ubutu/trusty64  실행 
 - 설정파일 열기 : config.vm.box  등 설정한다. 
 - vagrant up  :  
 - vagrant ssh  : 바그란트 설치된 우분투 서버에 접속할 수 있다. 
 
3. 하둡의 수행모드
 - 1. 스탠드얼론   :  HDFS 사용하지 않음, 서버 없이 간단한 프로그램 테스트용
        개발자가 간단한 수준의 테스트 
 - 2. 의사분산모드 (Pseudo Distributed Mode )
       : HDFS 사용, 한대의 서버에 모두 수행 :  네임노드, 데이터노드, 답트래커, 데이터노드
 - 3. 완전분산모드 (Full Distributed Mode) : HDFS 사용 , 각 서버를 여러 대의 시스셈에 나눠 수행, 
       하둡을 제대로 사용 
 
################  하둡 1.2.1 환경설정   스탠드얼론 형태로 수행

1. 하둡 다운로드 
    wget http://............hadoop-1.2.1.tar.gz)
2. 압축해제 tar xvfz    hadoop..........
3. 에디터 수정 : 환경변수
4. 환경변수 설정 및 저장(마지막에 추가)
   export HADOOP_HOME
   export PATH 
5. 환경설정 반영    : source
6. 환경변수 설정 확인 : echo .....
7.하둡 수행  : 스탠드얼론 형태로 수행
   hadoop.jar $HADOOP_HOME/hadoop-example-1.2.1.jar wordcount  $HADOP_HOME/README.txt ~/output
   
8.결과보기 
   nano /output/part-r-00000   
   -----  단어   숫자    :     cat    2  등 
   
#########  하둡 1.2.1 의사분산모드
1. 실행해야 할 서버
    HDFS  :  Name Node /  Seconday NameNode /    DataNode
    MapReduce :  jobtracker   TaskTracker 
2. ssh 골개키기반 자동로그인 설정
3. 환경설정 파일 설정 
   hadoop-env.sh  :   JAVA_HOME 설정
   mapred0site.xml
   hdfs-site.xml
   core-site.xml
   
4. HDFS 포맷
     hadoop namecode-format

5. 데몬 수행 및 수행확인 
   #] start-dfs.sh   start-mapred.sh
   
   #] jps ==>  5개 서버 떠 있는 확인 명령어

6. conf/hadoop-env.sh 수정   :  java 경로 수정 

7. java 홈 디렉토리 설정 

8. ssh 설지 
9. ssh 자동로그인 설정
   #] ssh-keygen-t dsa -p"" -f  ~/.ssh/id_dsa 
10. ssh localhost    자동로그인 확인  : 패스워드 묻지 않으면 성공 

12.   conf/hdfs-site.xml  
    dfs.replicatioin -- 1 복제 값을 1로 설정한다. 다수 서버가 없으니..
    
    -     conf/mapred-site.xml 수정 
        localhost:9001
        mapred.job.tracker

13. HDFS 포맷
     
14. 데몬 실행 

15 확인  :  jps
    프로세스 5개 떠야 한다.
    
16. 종료 : stop...sh

1##################### 
1. 도커를 기반으로 하둡을 실행하는 것의 장점에 대해 여러분의 생각을 입력해보세요
   -   하둡을 완전 분산모드로 실행하기 위해서는 여러 대의 시스템과 시스템별 설정이 필요합니다.
     만약 하이퍼바이저로 이를 설정하고 싶으면 다양한 문제가 발생합니다.
     가상머신별 os 설치 및 기본요구패키지 (자바, 하둡, 셋팅파일 설정 등) 설치해줘야 합니다
     그리고 개별 시스템의 리소스를 해줘야 합니다
     하지만 하둡을 사용하면 Dockedrfile 스크립트를 사용해 이미지(네임노드+잡트래커, 데이터노드+태스크트래커)
     를 생성해두고 필요한 컨테이너를 별도로 실행해주면 됩니다
     docker search 로 하둡 완전분산모드로 설치된 임지를 검색해서 다운받아도 된다는 것입니다. 

   
/*****************************************************
*  4. 하둡2 아키텍처 개선사항 및 설치
******************************************************/
1. Hadoop1 약점
  - 배치 최적화 : 맵/리듀스 형태의 작업에만 최적화 
  - 자원활용방법 문제점 :  잡트래커가 맵/리듀스작업이 잘되고 있는지 관리
  - 네임노드 SPOF (Single point of failure)  문제점 : 네임노드 , 세컨더리 네임노드 동시에 장애면 다운....   
  
2. Hadoop2 개선사항
 - 아키텍처 변화
 - 얀 (Yarn) 도입 : 자원(리소스) 관리 
    - 맵/리듀스 작업은 yarn 하나의 어플리케이션이됨 
      다른 형태의 서비스 지원 (스트리밍 포함)
      애플리케이션 마스터 (AM)  : 애플리케이션별 작업관리
      - 잡트래커 + 태스크트래커 -> 노드매니저 + 리소스매니저
      - 시스템 리소스활용 잡 진행상황관리를 분리 
 - 주키퍼 (zookeeper) 도입  : SPOF 해결 위해
    - 네임노드 고가용성 HA  : active-standby 
    - 리소스매니져 이중화

#######  hadoop2 설치 / 셋팅
1. 하둡2.X
 - 설정파일 위치 변경
 - 예제 위치 
 - 패키지명 변경 :   hadoop-core(1.X) -> hadoop-common(2.X)
 - 맵리듀스 수행정지는  start-yarn / stop-yarn 
   
## 전문가 의견 
하둡에코시스템의 특징은 기존 하둡의 기본 기능에 없거나 빈약한 기능을 보완하여 다양한 활용을
할 수 있도록 해주는 보완재라고 할 수 있다
하둡에 없는 RDBMS 접근 기능이나 웹서버로그를 하둡으로 올리는 기능 
SQL 쿼리 형태로 하둡을 사용하는 기능, NoSQL, 워크플로우, 머신러닝, 실시간 스트리밍 데이터 처리

스파크는 필요한 패키지를 기본적으로 한 번에 모두 제공한다
명확히 확장성과 효율성의 차이를 보여준다

 
/*****************************************************
* 5 빅데이터 예제 분석
******************************************************/

1.워드카운드 소스코드
 - 예제 코드 : plaintext -> mapper -> reducer ->  textoutputFormat
 - sample main
    각종 초기화 작업
    맵클래스 지정
    리듀스클래스 지정
    입력파일 위치 지정
    출력파일 위치 지정
    포맷형태지정
2, 하둡 프로그램의 구조 이해 및 기능추가
 - 워드카운트 프로그램에 구분자 추가
 - 컴바이너 추가  : 리듀스작업을 2단으로 구성해 리듀서의 작업량 감소 및 네트워크 부담 경감 (교환/결합법칙 필요  
 - 카운터 추가 
2. 맵 태스크 수의 결정방식
 - getsplit 메소드
 - inputSplit 마다 맵 태스트가 할당됨
 - 입력 파일의 수
 - 입력 파일의 크기
 - 입력 포맷의 변수
 
 3. 출력 포맷
  - 출력레코드 하나가 한라인
     키/밸류는 tab 으로 분리
     결과 파일의 압축 가능  : setCompressOutput  
     
4. 카운트 

5. WordCount Buil
 - ant maven2 gradle
 
6. Test Data  
 - wiki 샘플 데이터 2G   
 
 ######## 한글 처리 
 1. 일반적인 영어와 다름
 - 나는 나를 같은 단어임 
     나(어간) + 는(조사) ........   
 - 한글 문장은 전처리가 필요하다
   - 형태소분석기 필요
   - 오픈소스/상용 형태소 분석기
     - 은전한닢 : eunjeon.blogspot.kr 참조 

2. 한글을 처리하기 위해서는 형태소분석기를 통해 문장구조를 분석해서 전처리 후 (예 조사제거) 
하둡에서 처리해야 한다. 
   
3. 전문가 의견
- 하이브 Hive 와 같은 퀴리언어 스타일의 기술을 사용하는 장점?
 하둡은강력 확장성 장점, 
 
 하둡의 sting -> text 
/*****************************************************
* 6 하둡 결과물 후처리 및 워크플로우
******************************************************/
### wrdcount TopN (후처리)
1. 문제점 
 - 단순 단어별 빈도수만 나열
 - 일반 SQL order by , top /limt/rownum  --> 직접 프로그램을 짜야한다는 문제점 ..  
 - 작업  R과 같은 통계 툴에서 처리 
 - 워드카운트의 결과가 아주 많다면  하둡 자체에서 처리
   
2. 해결책
 - 데이터의 정렬  복잡하면서 시스템에 부하 줌 
    데이터가 증가하면 대략 제곱의 형태로 속도가 느려진다. O(N^2)   
    데이터가 10배 증가하면 속도는 100배 느려진다라는 뜻 
- 제일 많이/적게 나온 단어를 찾는 것은 쉽다 O(N)
- 자바의 자료구조 PriorityQueue  가장 많이 나오는 빈도의 단어 개수 파악

3. 프로그래밍 수행방식
 - 두개의 하둡.잡으로 분리
   - WordCount + TopN 사용
   - Oozie (워크플로우)  : 스크립트 작성  배치 파일 만든다 
   
###### 빅데이터와 통계(R)처리 결합방식
1. 하둡의 결과값 (주로 csv) 변환해 R의 입력으로 
2. 하둡과 통계오픈소스 R  결합해서 통계 처리     수작업으로 진행 
3. R-Hadoop : 통합솔루션 
   
### 전문가 : Oozie (워크플로우) 
하둡은 대량 데이터를 빠르게 처리하는 능력이 탁월하지만 통계처리와 같은 다양한 기능은 부족한 부분이 있다
이를 보완하기 위해 여러 개의 하둡잡을 연결시켜 원하는 결과를 만들어주는 워크플로우 툴이 필요
예를 들면 워드카운트 예제에서는 개별 단어의 빈도수만 분산처리해 대규모로 빠르게 계산해서 알려주는
것은 하둡이 탁월하지만 어떤 단어가 가장 많이 나왓는지 알아보려면 결과를 다시 재처리해야만 알 수 있다
이를 위해 여러 개의 하둡 작업을 연결해 입출력을 연결해 주는 워크플로우 툴이 필요하다. 
   
   
   
/*****************************************************
* 7 빅데이터 에코시스템(웹서버, RDBMS) - FLUME, SQOOP
******************************************************/
### 1. 하둡예코시스템

1. 하둡에서 제공하지 않는 기능을 보완 개선하는 패키지들을 모두 말하는 것
 - 하둡을 SQL 과 같은 쿼리언로 사용하게 해주는 하이브(Hive)
 - 하둡의 이력을 파일에서 RDBMS 를 사용하는 SQOOP
 - 웹서버 로그파일  Flume
 - 하둡의 분산파일 시스템인 HDFS 를 NoSQL 저장소로 만들어주는 HBase 
 
 예) HDFS , YARN, Hive, R Connectors,  Machout , pig, Oozie, Zookeeper, Ambari 등 


### 2. 스쿱 (Apache Sqoop) 스쿱

1.  RDMS -> HDFS -> RDBMS   :  RDBMS 데이터를 하둡에서 접근할 수 있게 만들어줌

2. Sqoop 기본적으로  Mysql 설치해야한다. 
   
### 3. 플룸 (Apache Flume)  

1. 웹 서버 로그파일을 하둡의 HDFS 업로드 해줌 

//### 하둡의 TextInputFormat 을 키/밸류형태로 변환해 처리하는 이유
하둡은 맵의 입력을 K1

/*****************************************************
* 빅데이터 에코시스템(쿼리, NoSQL) - HIVE, HBASE
******************************************************/
   
   
/*****************************************************
* 경량 분산처리 프레임워크-스파크 아키텍처 및 프로그래밍
******************************************************/
   
   
/*****************************************************
* 빅데이터와 컨테이너 기반 가상화 - 도커기반의 하둡
******************************************************/
   








