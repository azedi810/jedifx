 
/* ############################################################################
*  빅데이터 쉽게 이해하기
##############################################################################*/

/*****************************************************
*   101.빅데이터 개념 및 성공사례 
******************************************************/
1. 빅데이터의 개념
   - 현재는 상업적 마케팅ㅇ 용어로 변화 
   - 크리,   처리방식(병렬)   :   모두 만족  BIG DATA
   - 분산파일시스템 , 병렬처리 프레임워크 가지 있어야 한다.  
   - 대표적인 시스템 하둡 hadoop 
   
2. 빅데이터란
   - data 의미 : 데이터 다루는 기술 : dbms  주로 rdbms
   - 데이터 저장 검색 수정 삭제 
   - crud  : retrieve(검색)  주로 테이블 레코드 형태로 관리 
      - R : 데이터의 빠른 검색을 중심으로 최적화되어 있다.  데이터 변경보다 검색의 빈도가 압도적으로 많다.
        index 외 같은 보조 자료구조를 이미 만들어두고 검색에 사용해 검속 속도를 높인다. 
   
3. RDBMS   와  NoSQL 비교
    - DBMS 빠른 읽기 최적화  index 수정
    - NoSQL 등장 : 빠른 쓰기 최적
    - 하지만 양쪽 다 데이터가 커지는 경우 특수한 처리 필요 : 수십테라가 넘는 경우
    - 빅데이터는 일반적인 파일로 관리 (키/밸류 방식)
    
4. 빅데이터와 DBMS/NoSQL 차이점
   -  Big 의미 : 크기 
   - 일반 DBMS  : Large 데이터 다툼
   - Very Large DB  :  VLDB  : 조인이 거의 안됨 ,  역정규화 (Denormalize)  저장양이 많다   
       : 파티셔닝, 샤딩, 복제   -->  
       : 정규화 (데이터 중복 방지)
  - Big Data  :  VLDB 보다 크다  , 서버 수십대, 수백대, 수천대  , 데이터 분산 저장
      - 일반 DBMS 로 처리하려면 엄청난 비용 
      - 수십테라 이상 
      - 일반적인 DBMS 처리 못하는 것들
      - 서버 한 대로 처리할 수 없는 규모의 데이터  ( 예  10TB 쇼팅 1대 서버)
      - 기존 소프트웨어로 처리할 수 없는 규모의 데이터 
           
5. 빅데이터 성공 사례 
  - 데이터마이닝 :  넷플릭스 사례(영화 추천, 고객 만족도 높다, 영화카테고리, 배우 등)
      , 페이스북, 트위터
      , 월마트(상황 분석, 물건간의 상황, 주말-맥주 등  분석해서 동선 판매 위치 변경 성공)
  - 제일 문제는 데이터 :  데이터 주로 소유가 있음 : 자유롭게 유통 되지 않음
  - 작은 비용을 분석
  - 거의 유료가 없고, 오픈소스라 별다른 비용이 들지 않음 
  
   빅데이터 기술의 핵심은 여러 개의 시스템을 묶는 빅파일시스템인 HDFS (하둡시스템)와 분산처리 프레임워크인 맵리듀스(MapReduce)라고 할 수 있습니다
   멀티코어 시스템에서 여러 개의 코어를 활용하려면 멀티스레드 프로그래밍을 해야 합니다.
   이 방법은 하느이 코어만 사용하는 일반 프로그래밍보다 훨씬 복잡합니다.
   동기화라고 부르는 기술에 대한 이해가 필수 
   더욱이 데드락 deadlock 이라고 부르는 현상을 잡기는 굉장히 힘듬
   이를 DBMS에서 트랜잭션의 격리 isolation 라는 무제로 다룹니다.
   하지만 멀티스레드 프로그래밍을 하더라도 하나의 시스템의 범주를 벗어나기 흠듭니다.
   여러대의 시스템에 작업을 나누어주고 이를 취합하는 기술은 나이도가 괴장히 높습니다.
   그리고 일단 처리대상 데이터를 저장해야하는데 이를 분산저장하는 기술도 쉽지 않습니다
   즉 하둡의 핵심기술인 HDFS와 맵리듀스는 일반적인 개발가 다루기는 굉장히 복잡
   합둡은  개발자는 단진 HDFS 파일을 업로드 , 맵리듀스 작업에 대한 클래스만 프로그래밍해주면 됨 
   하둡은 오픈소스기술로 별도의 비용없이 사용, 
   초기에는 작게 시작했다가 시스템이 더 필요하면 간단한 작업으로 계속 스케일을 키울 수 있다 .
   
   
/*****************************************************
* 빅데이터 프레임워크 - 하둡 개요 및 아키텍처
******************************************************/
 1. 하둡의 역사
   - 더그 커팅  : 하둡의 아버지 , 루씬 제작자(검색엔진용 오픈 소스) . 구급의 영감을 얻어 
      10년 이상 개발된 빅데이터 처리를 위한 자바기반의 분산파일시스템 + 병렬처리 프레임워크 
   - 2003 : the google file system 논문 
   - mapreduce : 2004 : simplified data processing on large cluster    논문
   - 2006년 부터 제작 : apache top level project
   - 야후에 취직 -> 클라우데라로 이직
   - GFS ->HDFS ,   MapReduce -> MapReduce 
   - 노란색 코끼리 
   - Hadoop, Mahout(코끼리를 모는 사람), Oozie, Horton 
   
2. 하둡의 기초 사항
  - JAVA 로 만듦 :   
  - 유닉스 기반, 리눅스 중 우분투 기반으로 수업 진행
  - 배포판 : apache hadoop, CDH (믈라우데라판),  HDP (호튼웍스판)
  - 빅 3회사  : apache 재단  하둡 표준,  클라우데라(claudera : 가장크다)
                    호튼윅스(hortonworks) 야후 퇴사 후 
                    맵알 (MapR)
 3. 하둡의 특징
   - 오픈소스 , github 
   - 데이터가 있는 곳으로 코드를 이동
   - scale out  : 병렬 처리 ...서버를 하나씩 증가하는 방식 ==> 시스템을 지속 추가확장 가능한 스케일아웃구
   - 병렬처리를 가능하게 하는 단순한 데이터 모델
   - 오프라인 배치 프로세싱에 최적화 :  실시간 처리 안됨 
   
######. 하둡 아키텍처
  - 하둡  :    HDFS + MapReduce 
  - 빅파일시스템 HDFS  (Hadoop File System)
       - 네임노드(마스터) / 테이터노드 (슬레이브)  
           - 세컨더리 네임노드(보조네임노드사용 - 네임노드가 죽으면 서비스 장애가 생김) 
              : SPOF (single point of failure) 문제
   - 분산처리 프레임워크 : MapReduce
           - 잡트래커(마스터) / 태스트래커(슬레이브)

1. HDFS  
 - 고가용성 HA  high availiability   동일한 데이터블럭을 여러 번 복제해서 
    장애에도 문제없이 작동 가능하도록 만듬 
 - 하나의 HDFS 하나의 네임스페이스 제공 :  논리적 하나
 - 파일을 여러 개의 블럭으로 나누어 저장
 - 블록사이즈 : 64M   실제로 128M 많이 사용함
 - 큰 파일을 다루는 데 적합
 - 운영체제의 파일 시스템을 그대로 사용함.    포멧없이 사용
 - 복제수 (Replication Factor)  :  북제수가 3개면 3개 복제 : 장애 발생 시 괜찮다.
	 여러 군데에 같은 블럭을 복사    (HA)
 - file overWrite 형태로 구성됨 : 덮어씌운다.
 - 네임노드 +  데이터노드 
 
2. MapReduce
 - 잡트래커 + 태스크트래커 
    : 입력데이터 출력 HDFS 상에 존재 
 
3. MapReduce 프레임워크
 - word count process
   :  splitting      mapping       shuffling     reducing(복수 단어를 한단어로 줄여준다)       final result    
   
4. 스파크 기술과 하둡의 차이점에 대해서 적으시오   
   
/*****************************************************
* 3. 빅데이터 프레임워크 - 하둡 설치 및 준비사항(환경설정) 
******************************************************/
1. 설치 전제 조건
 - 하이퍼바이저 
     - 하이퍼바이저(버추얼박스)를 기반으로 리눅스(우분투)를 설치
     - Vagrant 사용해 설치를 자동화한다.
     - 도커(컨테이너기반)도 가능하지만 사용하는 법이 다르다.... 
 - 윈도우에 설치 : 하이퍼바이저나 도커 설치 (리눅스 인스톨)
 - 리눅스/유닉스 계열에서 네이티브로 바로 설치와 수행이 가능하다.  
 - 우분투 서버 이미지 다운로드   ubuntu  
  
2. vagrantup.com 바그란트   vagrant  
 - vagrnt int ubutu/trusty64  실행 
 - 설정파일 열기 : config.vm.box  등 설정한다. 
 - vagrant up  :  
 - vagrant ssh  : 바그란트 설치된 우분투 서버에 접속할 수 있다. 
 
3. 하둡의 수행모드
 - 1. 스탠드얼론   :  HDFS 사용하지 않음, 서버 없이 간단한 프로그램 테스트용
        개발자가 간단한 수준의 테스트 
 - 2. 의사분산모드 (Pseudo Distributed Mode )
       : HDFS 사용, 한대의 서버에 모두 수행 :  네임노드, 데이터노드, 답트래커, 데이터노드
 - 3. 완전분산모드 (Full Distributed Mode) : HDFS 사용 , 각 서버를 여러 대의 시스셈에 나눠 수행, 
       하둡을 제대로 사용 
 
################  하둡 1.2.1 환경설정   스탠드얼론 형태로 수행

1. 하둡 다운로드 
    wget http://............hadoop-1.2.1.tar.gz)
2. 압축해제 tar xvfz    hadoop..........
3. 에디터 수정 : 환경변수
4. 환경변수 설정 및 저장(마지막에 추가)
   export HADOOP_HOME
   export PATH 
5. 환경설정 반영    : source
6. 환경변수 설정 확인 : echo .....
7.하둡 수행  : 스탠드얼론 형태로 수행
   hadoop.jar $HADOOP_HOME/hadoop-example-1.2.1.jar wordcount  $HADOP_HOME/README.txt ~/output
   
8.결과보기 
   nano /output/part-r-00000   
   -----  단어   숫자    :     cat    2  등 
   
#########  하둡 1.2.1 의사분산모드
1. 실행해야 할 서버
    HDFS  :  Name Node /  Seconday NameNode /    DataNode
    MapReduce :  jobtracker   TaskTracker 
2. ssh 골개키기반 자동로그인 설정
3. 환경설정 파일 설정 
   hadoop-env.sh  :   JAVA_HOME 설정
   mapred0site.xml
   hdfs-site.xml
   core-site.xml
   
4. HDFS 포맷
     hadoop namecode-format

5. 데몬 수행 및 수행확인 
   #] start-dfs.sh   start-mapred.sh
   
   #] jps ==>  5개 서버 떠 있는 확인 명령어

6. conf/hadoop-env.sh 수정   :  java 경로 수정 

7. java 홈 디렉토리 설정 

8. ssh 설지 
9. ssh 자동로그인 설정
   #] ssh-keygen-t dsa -p"" -f  ~/.ssh/id_dsa 
10. ssh localhost    자동로그인 확인  : 패스워드 묻지 않으면 성공 

12.   conf/hdfs-site.xml  
    dfs.replicatioin -- 1 복제 값을 1로 설정한다. 다수 서버가 없으니..
    
    -     conf/mapred-site.xml 수정 
        localhost:9001
        mapred.job.tracker

13. HDFS 포맷
     
14. 데몬 실행 

15 확인  :  jps
    프로세스 5개 떠야 한다.
    
16. 종료 : stop...sh

1##################### 
1. 도커를 기반으로 하둡을 실행하는 것의 장점에 대해 여러분의 생각을 입력해보세요
   -   하둡을 완전 분산모드로 실행하기 위해서는 여러 대의 시스템과 시스템별 설정이 필요합니다.
     만약 하이퍼바이저로 이를 설정하고 싶으면 다양한 문제가 발생합니다.
     가상머신별 os 설치 및 기본요구패키지 (자바, 하둡, 셋팅파일 설정 등) 설치해줘야 합니다
     그리고 개별 시스템의 리소스를 해줘야 합니다
     하지만 하둡을 사용하면 Dockedrfile 스크립트를 사용해 이미지(네임노드+잡트래커, 데이터노드+태스크트래커)
     를 생성해두고 필요한 컨테이너를 별도로 실행해주면 됩니다
     docker search 로 하둡 완전분산모드로 설치된 임지를 검색해서 다운받아도 된다는 것입니다. 

   
/*****************************************************
* 빅데이터 프레임워크 - 하둡2 아키텍처 개선사항 및 설치
******************************************************/
1. Hadoop2 개선 사항
  - 배치 최적화 : 맵/리듀스 형태의 작업에만 최적화 
  - 자원활용방법 문제점 :  
  
   
/*****************************************************
* 빅데이터 프로그래밍 - 빅데이터 예제 분석
******************************************************/
   
   
/*****************************************************
* 빅데이터 프로그래밍 - 하둡 결과물 후처리 및 워크플로우
******************************************************/
   
   
/*****************************************************
* 빅데이터 에코시스템(웹서버, RDBMS) - FLUME, SQOOP
******************************************************/
   
   
/*****************************************************
* 빅데이터 에코시스템(쿼리, NoSQL) - HIVE, HBASE
******************************************************/
   
   
/*****************************************************
* 경량 분산처리 프레임워크-스파크 아키텍처 및 프로그래밍
******************************************************/
   
   
/*****************************************************
* 빅데이터와 컨테이너 기반 가상화 - 도커기반의 하둡
******************************************************/
   








